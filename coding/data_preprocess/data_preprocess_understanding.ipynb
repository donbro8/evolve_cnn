{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **execute_preprocessing_all_files** (Train helper)\n",
    "\n",
    "    1.1) parameters listed below\n",
    "\n",
    "2) **execute_audio_extraction** (loops through and extracts the segments from the audio files)\n",
    "\n",
    "    2.1) Parameters: audio_directory, file_name, sample_rate, timestamp_directory, number_seconds_to_extract, save_location\n",
    "\n",
    "    2.2) file_name is obtained from training_files.txt (can maybe just scan the directory to get the file names and create file)\n",
    "\n",
    "    2.3) all other input parameters accounted for.\n",
    "\n",
    "    2.4) Outputs: gibbon_extracted, non_gibbon_extracted\n",
    "\n",
    "3) **execute_augmentation** (augment the extracted segments)\n",
    "\n",
    "    3.1) Parameters: gibbon_extracted, non_gibbon_extracted, number_seconds_to_extract, sample_rate, augmentation_amount_noise, augmentation_probability, augmentation_amount_gibbon, seed, augment_directory, augment_image_directory, file_name\n",
    "\n",
    "    3.2) Outputs: gibbon_extracted_augmented_image, non_gibbon_extracted_augmented_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execute_audio_extraction  \n",
    "*extracts the segments from the audio files*\n",
    "\n",
    "1) **execute_audio_extraction** (details as above in point 2 - Train helper)\n",
    "\n",
    "2) load audio files using librosa.load \n",
    "\n",
    "    2.1) Inputs: audio_directory + file_name, sample_rate\n",
    "\n",
    "    2.2) Ouputs: librosa_audio, librosa_sample_rate\n",
    "\n",
    "3) **read_and_process_gibbon_timestamps** (Extract_Audio_Helper)\n",
    "\n",
    "    3.1) Inputs: timestamp_directory, 'g_'+file_name[:file_name.find('.wav')]+'.data', sample_rate, sep=','\n",
    "\n",
    "    3.2) Outputs: gibbon_timestamps Pandas dataframe with columns Start, End, Duration, Type (number of pulses)\n",
    "\n",
    "4) **read_and_process_nongibbon_timestamps** (Extract_Audio_Helper)\n",
    "\n",
    "    4.1) Inputs: timestamp_directory, 'n_'+file_name[:file_name.find('.wav')]+'.data', sample_rate, sep=','\n",
    "\n",
    "    4.2) Outputs: nongibbon_timestamps dataframe Pandas dataframe with columns Start, End\n",
    "\n",
    "5) **extract_all_gibbon_calls** (Extract_Audio_Helper)\n",
    "\n",
    "    5.1) Inputs: librosa_audio, gibbon_timestamp_df = None, alpha=10, jump_seconds=1 ,sample_rate = 0, verbose=0 (librosa_audio, gibbon_timestamps,\n",
    "                                            number_seconds_to_extract,1, librosa_sample_rate,0)\n",
    "\n",
    "    5.2) Outputs: gibbon_extracted\n",
    "\n",
    "6) **extract_all_nongibbon_calls** (Extract_Audio_Helper)\n",
    "\n",
    "    6.1) Inputs: librosa_audio, gibbon_timestamp_df = None, alpha=10, jump_seconds=1 ,sample_rate = 0, verbose=0 (librosa_audio, non_gibbon_timestamps, number_seconds_to_extract, 5, librosa_sample_rate, 0)\n",
    "\n",
    "    6.2) Outputs: noise_extracted\n",
    "\n",
    "7) pickle.dump (saves extracted files to save location)\n",
    "\n",
    "    7.1) pickle.dump(gibbon_extracted, open(save_location+'g_'+file_name[:file_name.find('.wav')]+'.pkl', \"wb\" ))\n",
    "    \n",
    "    7.2) pickle.dump(noise_extracted, open(save_location+'n_'+file_name[:file_name.find('.wav')]+'.pkl', \"wb\" )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execute_augmentation  \n",
    "*augment the extracted segments*\n",
    "\n",
    "1) **execute_augmentation** (details as above in point 3 - Train helper)\n",
    "\n",
    "2) print shape of gibbon_extracted and non_gibbon_extracted\n",
    "\n",
    "3) **augment_background** (add noise to background data - Augmentation)\n",
    "\n",
    "    3.1) Inputs: seed, augmentation_amount, augmentation_probability, background_noise, sample_rate, alpha\n",
    "\n",
    "    3.2) Outputs: augmented data as array\n",
    "\n",
    "    3.3) **time_shift** (background_data, random_time_point, sample_rate)\n",
    "    \n",
    "        3.3.1) Inputs: audio, time, sample_rate\n",
    "\n",
    "4) **augment_data** (add noise to background data - Augmentation)\n",
    "\n",
    "    3.1) Inputs: seed, augmentation_amount, augmentation_probability, gibbon_calls, background_noise, sample_rate, alpha\n",
    "\n",
    "    3.2) Outputs: nongibbon_timestamps dataframe Pandas dataframe with columns Start, End\n",
    "\n",
    "5) **extract_all_gibbon_calls** (Extract_Audio_Helper)\n",
    "\n",
    "    5.1) Inputs: librosa_audio, gibbon_timestamp_df = None, alpha=10, jump_seconds=1 ,sample_rate = 0, verbose=0 (librosa_audio, gibbon_timestamps,\n",
    "                                            number_seconds_to_extract,1, librosa_sample_rate,0)\n",
    "\n",
    "    5.2) Outputs: gibbon_extracted\n",
    "\n",
    "6) **extract_all_nongibbon_calls** (Extract_Audio_Helper)\n",
    "\n",
    "    6.1) Inputs: librosa_audio, gibbon_timestamp_df = None, alpha=10, jump_seconds=1 ,sample_rate = 0, verbose=0 (librosa_audio, non_gibbon_timestamps, number_seconds_to_extract, 5, librosa_sample_rate, 0)\n",
    "\n",
    "    6.2) Outputs: noise_extracted\n",
    "\n",
    "7) pickle.dump (saves extracted files to save location)\n",
    "\n",
    "    7.1) pickle.dump(gibbon_extracted, open(save_location+'g_'+file_name[:file_name.find('.wav')]+'.pkl', \"wb\" ))\n",
    "    \n",
    "    7.2) pickle.dump(noise_extracted, open(save_location+'n_'+file_name[:file_name.find('.wav')]+'.pkl', \"wb\" )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 4800\n",
    "number_seconds_to_extract = 10\n",
    "seed = 42\n",
    "number_iterations = 1\n",
    "augmentation_probability = 1.0\n",
    "augmentation_amount_noise = 2\n",
    "augmentation_amount_gibbon = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory = 'raw_data/train/'\n",
    "timestamp_directory = 'raw_data/train_labels/'\n",
    "save_location = 'pickled_data/'\n",
    "augment_directory = 'augmented_data/'\n",
    "augment_image_directory = 'augmented_image_data/'\n",
    "training_file = 'training_files.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_preprocessing_all_files(training_file, audio_directory, \n",
    "                            sample_rate, timestamp_directory,\n",
    "                            number_seconds_to_extract, save_location,\n",
    "                            augmentation_amount_noise, augmentation_probability, \n",
    "                            augmentation_amount_gibbon, seed, augment_directory, augment_image_directory,\n",
    "                            number_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing set preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory = 'raw_data/test/'\n",
    "timestamp_directory = 'raw_data/test_labels/'\n",
    "save_location = 'raw_data/test/pickled_data/'\n",
    "augment_directory = 'raw_data/test/augmented_data/'\n",
    "augment_image_directory = 'raw_data/test/augmented_image_data/'\n",
    "testing_file = 'testing_files.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_preprocessing_all_files(testing_file, audio_directory, \n",
    "                            sample_rate, timestamp_directory,\n",
    "                            number_seconds_to_extract, save_location,\n",
    "                            augmentation_amount_noise, augmentation_probability, \n",
    "                            augmentation_amount_gibbon, seed, augment_directory, augment_image_directory,\n",
    "                            number_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_training_images(augment_image_directory, training_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3647436c2f734fd3f72be8f73130b09ecd5d6c908b22991734a3f7b2100497cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
