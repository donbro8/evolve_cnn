{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Branches\n",
    "- Connections\n",
    "- Layers\n",
    "    - Input\n",
    "        - Input shape (first input is standard, all others are calculated)\n",
    "        - Batch size \n",
    "    - 2D convolutional\n",
    "        - Filters\n",
    "        - Kernel size\n",
    "        - Padding\n",
    "        - Activation\n",
    "    - Pooling\n",
    "        - Max\n",
    "            - Size\n",
    "            - Strides\n",
    "            - Padding\n",
    "        - Average\n",
    "            - Size\n",
    "            - Strides\n",
    "            - Padding\n",
    "    - Dropout\n",
    "        - Rate\n",
    "    - Batch normalisation\n",
    "    - Concatenate\n",
    "        - Axis\n",
    "    - Flatten\n",
    "    - Dense\n",
    "        - Units (1, 2)\n",
    "        - Activation (sigmoid, softmax)\n",
    "    - Global pooling\n",
    "        - Max\n",
    "        - Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GA\n",
    "    - Type\n",
    "    - Number of generations\n",
    "- Population\n",
    "    - Size\n",
    "    - Encoding type\n",
    "    - Individual size\n",
    "        - Variable or fixed\n",
    "- Fitness\n",
    "- Selection\n",
    "- Reproduction\n",
    "- Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial import distance\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, MaxPool2D, AveragePooling2D, Conv2D, Input, SpatialDropout2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'input':{\n",
    "        'batch':[8, 16, 32] # input batch size\n",
    "        },\n",
    "    'conv':{\n",
    "        'kernel':[1, 3, 5, 7], \n",
    "        'filter':[2, 4, 8, 16],\n",
    "        'padding':['valid', 'same'],\n",
    "        'activation':['tanh', 'relu', 'selu', 'elu']\n",
    "        },\n",
    "    'pool':{\n",
    "        'type':['max', 'average'],\n",
    "        'size':[2, 3, 4, 5],\n",
    "        'padding':['valid', 'same']\n",
    "        },\n",
    "    'dropout':{\n",
    "        'type':['dropout','spatial2D'],\n",
    "        'rate':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        },\n",
    "    'output':{\n",
    "        'type':['global', 'dense']\n",
    "        }\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual = [\n",
    "    # Input layer\n",
    "    'batch_size_index', \n",
    "    \n",
    "    # Convolutional layer\n",
    "    'kernel_index', 'filter_index', 'padding_index', 'activation_index',\n",
    "\n",
    "    # Pooling layer\n",
    "    'type_index', 'size_index', 'padding_index',\n",
    "\n",
    "    # Dropout layer\n",
    "    'type_index', 'rate_index',\n",
    "\n",
    "    # Output layer\n",
    "    'type_index',\n",
    "\n",
    "    # Add layer\n",
    "    ## Layer/Branch 1\n",
    "    'indicator', 'branch_indicator', 'type', 'from', 'to',\n",
    "\n",
    "    ## Layer/Branch 2\n",
    "    'indicator', 'branch_indicator', 'type', 'from', 'to',\n",
    "\n",
    "    ## ... variable length array\n",
    "\n",
    "    ## Layer/Branch n\n",
    "    'indicator', 'branch_indicator', 'type', 'from', 'to'\n",
    "\n",
    "\n",
    "    ]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_space(parameters):\n",
    "\n",
    "    \"\"\"\n",
    "    Get the encoding length of an individual based on the input parameters dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    len_lists = []\n",
    "    len_values = [] # stores the maximum lengths of bits required to define the length of the lists in the parameters dict\n",
    "    # max_ind = []\n",
    "    # bit_max_int = []\n",
    "    # bit_max = ''\n",
    "\n",
    "    for layer in params.keys():\n",
    "\n",
    "            for value_list in list(params[layer].values()):\n",
    "\n",
    "                # max_ind.append(len(value_list) - 1)\n",
    "\n",
    "                # bit_max = bit_max + bin(len(value_list) - 1)[2:]\n",
    "\n",
    "                len_values.append(len(bin(len(value_list) - 1)[2:])) \n",
    "\n",
    "                len_lists.append(len(value_list))\n",
    "        \n",
    "\n",
    "    gene_length = np.max(len_values)\n",
    "    \n",
    "    individual_length = len(len_lists) * gene_length\n",
    "\n",
    "    # len_values = np.array(len_values)\n",
    "\n",
    "    len_lists = np.array(len_lists)\n",
    "\n",
    "    return individual_length, gene_length, len_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 4 [3 4 4 2 4 2 4 2 2 9 2]\n"
     ]
    }
   ],
   "source": [
    "ind_len, gene_len, len_list = get_state_space(params)\n",
    "print(ind_len, gene_len, len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(length, parameter_len, n = 10, seed = None):\n",
    "    \"\"\"\n",
    "    Generate population given the number of individuals in a population and the the required binary length\n",
    "    \"\"\"\n",
    "\n",
    "    bit_length = int(length/len(parameter_len))\n",
    "\n",
    "    if seed != None:\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    population = np.zeros(shape=(n, length), dtype=int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        bits = ''\n",
    "        for l in parameter_len:\n",
    "\n",
    "            choice = np.random.choice(np.arange(0, l))\n",
    "\n",
    "            bit_choice = bin(choice)[2:]\n",
    "\n",
    "            bits += ('0' * (bit_length - len(bit_choice))) + bit_choice\n",
    "\n",
    "        population[i] = np.array([int(x) for x in bits])\n",
    "    \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      "  0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1\n",
      "  0 0 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "pop = generate_population(ind_len, len_list, n = 100, seed = 43)\n",
    "print(pop[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(chromosome, gene_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Converts the binary bitstring vector to integer phenotype and performs check to see if it is valid with respect to the constraints\n",
    "    \"\"\"\n",
    "\n",
    "    chromo_length = len(chromosome)\n",
    "\n",
    "    start_ind = np.arange(0, chromo_length, gene_length)\n",
    "\n",
    "    phenotype = np.array([int(str(''.join(map(str, chromosome[x:x + gene_length]))), 2) for x in start_ind])\n",
    "\n",
    "    # is_valid = np.any(phenotype < parameter_lengths - 1)\n",
    "\n",
    "    return phenotype #, is_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 1 1 0 0 1 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "pheno = decoder(pop[0], gene_len)\n",
    "print(pheno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(phenotype, parameter_lengths):\n",
    "    return np.any(phenotype < parameter_lengths - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "valid = validity_check(pheno, len_list)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(population, selection_probability = 0.1, seed = None):\n",
    "\n",
    "    n = population.shape[0]\n",
    "\n",
    "    n_select = int(np.ceil(n*selection_probability))\n",
    "\n",
    "    mean_hamming = 0\n",
    "\n",
    "    if seed != None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    for individual in np.random.choice(np.arange(0, n, n_select), n_select):\n",
    "\n",
    "        mean_hamming += np.mean([distance.hamming(population[individual], population[x]) for x in range(n)])\n",
    "\n",
    "    return mean_hamming/n_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20345454545454547"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_distance(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(fitness_input, population = None, model_params = None, age = None, beta = 10):\n",
    "\n",
    "    diversity = 1\n",
    "\n",
    "    n_params = 1\n",
    "\n",
    "    if population != None:\n",
    "        diversity = hamming_distance(population)\n",
    "\n",
    "    if model_params != None:\n",
    "        n_params = 1 # need to determine the maximum number of possible parameters so that we can scale\n",
    "\n",
    "    return 1/(1 + np.exp(-beta*fitness_input)) # * 1/diversity * n_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_parent_similarity(parents):\n",
    "    return np.any(np.sum(np.diff(parents, axis = 0), axis = 1) == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_parent_similarity(np.array([[1,0,0,1], [1,1,1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 44)\n",
      "(100, 44)\n"
     ]
    }
   ],
   "source": [
    "print(pop.shape)\n",
    "print(crossover(pop).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(phenotype, parameters):\n",
    "\n",
    "    params = []\n",
    "\n",
    "    layers = list(parameters.keys())\n",
    "\n",
    "    param_count = 0\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "\n",
    "        for param_type in parameters[layers[i]].keys():\n",
    "            \n",
    "            params.append(parameters[layers[i]][param_type][phenotype[param_count]])\n",
    "            \n",
    "            param_count += 1\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 1, 16, 'same', 'relu', 'max', 2, 'same', 'spatial2D', 0.3, 'global']\n"
     ]
    }
   ],
   "source": [
    "new_params = get_params(pheno, params)\n",
    "print(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(sample_size = None, seed = None):\n",
    "    \n",
    "    X = np.load('/Users/Donovan/Documents/Masters/masters-ed02/coding/model_base_cnn/train/X.npy')\n",
    "    Y = np.load('/Users/Donovan/Documents/Masters/masters-ed02/coding/model_base_cnn/train/Y.npy')\n",
    "\n",
    "    # Subsample\n",
    "    if sample_size != None:\n",
    "        g_sample = int(np.floor(sample_size/2))\n",
    "        n_sample = sample_size - g_sample\n",
    "\n",
    "        g_i = np.random.randint(0, int(X.shape[0]/2) - 1, g_sample)\n",
    "        n_i = np.random.randint(int(X.shape[0]/2), X.shape[0] - 1, n_sample)\n",
    "\n",
    "        X = np.concatenate([X[g_i], X[n_i]])\n",
    "        Y = np.concatenate([Y[g_i], Y[n_i]])\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.40, random_state=seed, shuffle = True)\n",
    "        X_test, X_val, Y_test, Y_val = train_test_split(X_val, Y_val, test_size=0.50, random_state=seed, shuffle = True)\n",
    "\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.40, random_state=seed, shuffle = True)\n",
    "        X_test, X_val, Y_test, Y_val = train_test_split(X_val, Y_val, test_size=0.50, random_state=seed, shuffle = True)\n",
    "\n",
    "    return  {'X_train':X_train, 'X_val':X_val, 'X_test':X_test, 'Y_train':Y_train, 'Y_val':Y_val, 'Y_test':Y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (600, 128, 188, 1)\n",
      "Y_train: (600, 2)\n",
      "\n",
      "X_val: (200, 128, 188, 1)\n",
      "Y_val: (200, 2)\n",
      "\n",
      "X_val: (200, 128, 188, 1)\n",
      "Y_val: (200, 2)\n"
     ]
    }
   ],
   "source": [
    "data_dict = prep_data(sample_size = 1000, seed = 42)\n",
    "\n",
    "print ('X_train:',data_dict['X_train'].shape)\n",
    "print ('Y_train:',data_dict['Y_train'].shape)\n",
    "print ()\n",
    "print ('X_val:',data_dict['X_val'].shape)\n",
    "print ('Y_val:',data_dict['Y_val'].shape)\n",
    "print ()\n",
    "print ('X_val:',data_dict['X_test'].shape)\n",
    "print ('Y_val:',data_dict['Y_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(parameters, X_train, X_val, Y_train, Y_val, verbose = 0):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(input_shape = X_train.shape[1:], kernel_size = parameters[1], filters = parameters[2], padding = parameters[3],\n",
    "                        activation = parameters[4]))\n",
    "\n",
    "    if parameters[8] == 'dropout':\n",
    "        model.add(Dropout(rate = parameters[9]))\n",
    "\n",
    "    else:\n",
    "        model.add(SpatialDropout2D(rate = parameters[9]))\n",
    "\n",
    "    if parameters[5] == 'max':\n",
    "        model.add(MaxPool2D(pool_size=parameters[6], padding=parameters[7]))\n",
    "\n",
    "    else:\n",
    "        model.add(AveragePooling2D(pool_size=parameters[6], padding=parameters[7]))\n",
    "\n",
    "    if parameters[10] == 'dense':\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation = parameters[4]))\n",
    "        model.add(Dropout(rate = parameters[9]))\n",
    "\n",
    "\n",
    "    else:\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "            batch_size=parameters[0],\n",
    "            epochs=10,\n",
    "            verbose=verbose, \n",
    "            class_weight={0:1.,1:1.})\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:03:16.957267: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-27 19:03:16.959011: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:03:17.428313: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-27 19:03:18.268470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 - 2s - loss: 0.6932 - acc: 0.4983 - f1_m: 0.4983 - precision_m: 0.4983 - recall_m: 0.4983 - val_loss: 0.6941 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 2s/epoch - 29ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 19:03:19.444787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 - 1s - loss: 0.6928 - acc: 0.5150 - f1_m: 0.5150 - precision_m: 0.5150 - recall_m: 0.5150 - val_loss: 0.6944 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 824ms/epoch - 11ms/step\n",
      "Epoch 3/10\n",
      "75/75 - 1s - loss: 0.6924 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6946 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 809ms/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "75/75 - 1s - loss: 0.6930 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6955 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 814ms/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "75/75 - 1s - loss: 0.6931 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6953 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 808ms/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "75/75 - 1s - loss: 0.6928 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6954 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 889ms/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "75/75 - 1s - loss: 0.6929 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6954 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 787ms/epoch - 10ms/step\n",
      "Epoch 8/10\n",
      "75/75 - 1s - loss: 0.6926 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6957 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 877ms/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "75/75 - 1s - loss: 0.6929 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6954 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 853ms/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "75/75 - 1s - loss: 0.6931 - acc: 0.5133 - f1_m: 0.5133 - precision_m: 0.5133 - recall_m: 0.5133 - val_loss: 0.6957 - val_acc: 0.4550 - val_f1_m: 0.4550 - val_precision_m: 0.4550 - val_recall_m: 0.4550 - 842ms/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(new_params, data_dict['X_train'], data_dict['X_val'], data_dict['Y_train'], data_dict['Y_val'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "fitness_val = fitness(np.mean(np.diff(history.history['val_f1_m'])))\n",
    "print(fitness_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population, data_dict, parameter_set, gene_length, k = 2, selection_probability = 0.9, seed = None, verbose = 0):\n",
    "\n",
    "    population_size = population.shape[0]\n",
    "\n",
    "    individual_length = population.shape[1]\n",
    "\n",
    "    selected_population_size = 0\n",
    "\n",
    "    if seed != None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    while selected_population_size < population_size:\n",
    "\n",
    "        sub_population = population[np.random.choice(np.arange(0, population_size, 1), k, replace = False)]\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        iteration = 1\n",
    "\n",
    "        for individual in sub_population:\n",
    "\n",
    "            # train model outside of this function then provide fitness scores as parameter\n",
    "\n",
    "            phenotype = decoder(individual, gene_length)\n",
    "\n",
    "            params = get_params(phenotype, parameter_set)\n",
    "\n",
    "            model, history = train_model(params, data_dict['X_train'], data_dict['X_val'], data_dict['Y_train'], data_dict['Y_val'], verbose = verbose)\n",
    "\n",
    "            scores.append(fitness(np.mean(np.diff(history.history['val_f1_m']))))\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        \n",
    "        rank_index = np.argsort(scores)\n",
    "\n",
    "        rank_scores = np.array(scores)[rank_index]\n",
    "\n",
    "        ranked = sub_population[rank_index]\n",
    "\n",
    "        p_array = np.concatenate(([selection_probability], selection_probability*((1 - selection_probability)**rank_scores)))\n",
    "\n",
    "        p_array = np.concatenate((p_array[p_array < 1], np.array([1 - np.sum(p_array[p_array < 1])])))\n",
    "\n",
    "        p_array = np.concatenate((p_array[0:len(ranked) - 1], [np.sum(p_array[len(ranked) - 1:])]))[rank_index]\n",
    "\n",
    "        selected_index = np.random.choice(rank_index, p = p_array)\n",
    "\n",
    "        selected = ranked[selected_index]\n",
    "\n",
    "        fitness_val = rank_scores[selected_index]\n",
    "\n",
    "        if selected_population_size == 0:\n",
    "            \n",
    "            selected_population = selected\n",
    "\n",
    "            selected_fitness = np.array([fitness_val])\n",
    "\n",
    "            selected_population_size = 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            selected_population = np.vstack((selected_population, selected))\n",
    "\n",
    "            selected_fitness = np.concatenate((selected_fitness, np.array([fitness_val])))\n",
    "\n",
    "            selected_population_size = selected_population.shape[0]\n",
    "\n",
    "    return selected_population, selected_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection(pop[-2:], data_dict, params, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(selected_population, gene_length, n_parents = 2, crossover_probability = 1.0, seed = None, verbose = 0):\n",
    "\n",
    "    population_size = selected_population.shape[0]\n",
    "\n",
    "    individual_length = selected_population.shape[1]\n",
    "\n",
    "    size_tuple = (n_parents, individual_length)\n",
    "\n",
    "    offspring_population_size = 0\n",
    "\n",
    "    while offspring_population_size < population_size:\n",
    "\n",
    "        similar_parents = False\n",
    "\n",
    "        while not similar_parents:\n",
    "\n",
    "            parent_index = np.random.choice(np.arange(0, population_size, 1), n_parents, replace = False)\n",
    "\n",
    "            parents = selected_population[parent_index]\n",
    "\n",
    "            similar_parents = check_parent_similarity(parents)\n",
    "\n",
    "        if seed != None:\n",
    "            np.random.seed(42)\n",
    "\n",
    "        r = np.random.random()\n",
    "\n",
    "        if crossover_probability < 1.0 and crossover_probability > 0.0 and r > crossover_probability:\n",
    "\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "\n",
    "            offspring = np.zeros(size_tuple)\n",
    "\n",
    "            for i in range(n_parents):\n",
    "\n",
    "                valid_individual = False\n",
    "\n",
    "                while not valid_individual:\n",
    "\n",
    "                    random_matrix = np.random.random(size_tuple)\n",
    "\n",
    "                    normalised_random_matrix = random_matrix/random_matrix.sum(axis = 0)\n",
    "\n",
    "                    max_index_j = np.argmax(normalised_random_matrix, axis = 0)\n",
    "\n",
    "                    offspring_v = parents[max_index_j, range(individual_length)]\n",
    "\n",
    "                    phenotype = decoder(offspring_v, gene_length)\n",
    "\n",
    "                    valid_individual = validity_check(phenotype)\n",
    "                    \n",
    "                offspring[i] = offspring_v\n",
    "\n",
    "        if offspring_population_size == 0:\n",
    "\n",
    "            offspring_population = offspring\n",
    "\n",
    "        else:\n",
    "\n",
    "            offspring_population = np.vstack((offspring_population, offspring))\n",
    "\n",
    "        offspring_population_size = offspring_population.shape[0]\n",
    "\n",
    "    return offspring_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(offspring, mutation_probability = 0.05):\n",
    "\n",
    "    r = np.random.random((offspring.shape))\n",
    "\n",
    "    mutated_offspring = np.copy(offspring)\n",
    "\n",
    "    mutate_index = (r < mutation_probability)\n",
    "\n",
    "    mutated_offspring[mutate_index] = np.logical_not(mutated_offspring[mutate_index])\n",
    "\n",
    "    return mutated_offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(parameters, data_dict, generations = 10, n_parents = 2, verbose = 0):\n",
    "\n",
    "    print('Getting state space parameters....')\n",
    "\n",
    "    individual_length, bit_length, parameter_list_lengths = get_state_space(parameters=parameters)\n",
    "\n",
    "    print(f'Chromosome length = {individual_length}; Gene length = {bit_length}; Possible number of choices per parameter = {parameter_list_lengths}')\n",
    "\n",
    "    print(20*'_')\n",
    "\n",
    "    print('Generating population....')\n",
    "\n",
    "    population = generate_population(length = individual_length, parameter_len = parameter_list_lengths)\n",
    "\n",
    "    population_size = population.shape[0]\n",
    "\n",
    "    print(f'Population size = {population_size}')\n",
    "\n",
    "    generation_history = {}\n",
    "\n",
    "    for generation in range(generations):\n",
    "\n",
    "        g = 1\n",
    "\n",
    "        print(20*'_')\n",
    "\n",
    "        print(f'_Generation {g} of {generations}.')\n",
    "\n",
    "        selected_population, selected_fitness = selection(population, data_dict, parameters, bit_length)\n",
    "\n",
    "        offspring_population = crossover(selected_population)\n",
    "\n",
    "        offspring_population = mutation(offspring_population)\n",
    "\n",
    "        offspring_fitness = []\n",
    "\n",
    "        for individual in offspring_population:\n",
    "\n",
    "            phenotype = decoder(individual, bit_length)\n",
    "\n",
    "            params = get_params(phenotype, parameters)\n",
    "\n",
    "            model, history = train_model(params, data_dict['X_train'], data_dict['X_val'], data_dict['Y_train'], data_dict['Y_val'], verbose = verbose)\n",
    "\n",
    "            offspring_fitness.append(fitness(np.mean(np.diff(history.history['val_f1_m']))))\n",
    "\n",
    "        total_pool = np.vstack((selected_population, offspring_population))\n",
    "\n",
    "        total_fitness = np.concatenate((selected_fitness, np.array(offspring_fitness)))\n",
    "\n",
    "        new_population_index = np.argsort(total_fitness)[::-1][:population_size]\n",
    "\n",
    "        population = total_pool[new_population_index]\n",
    "\n",
    "        generation_history[str(g)]['population'] = population\n",
    "\n",
    "        generation_history[str(g)]['fitness'] = total_fitness[new_population_index]\n",
    "            \n",
    "        g += 1\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    return generation_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting state space parameters....\n",
      "Chromosome length = 44; Gene length = 4; Possible number of choices per parameter = [3 4 4 2 4 2 4 2 2 9 2]\n",
      "____________________\n",
      "Generating population....\n",
      "Population size = 10\n",
      "____________________\n",
      "_Generation 1 of 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 06:55:37.042799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:55:39.288425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:55:51.614480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:55:53.152461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:02.270702: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:03.791967: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:14.019983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:15.142406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:21.548228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:22.984218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:32.832870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:33.996600: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:41.112828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:42.659124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:55.197110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:56:56.386970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:05.444638: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:06.834731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:16.560801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:17.608162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:21.732280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:23.228921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:36.533145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:37.829308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:46.620782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:47.632130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:54.013739: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:57:55.062693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:02.483697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:03.602480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:12.535479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:13.653806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:21.505324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:23.060618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:35.249484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:36.352720: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:44.030916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:45.558910: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:58:58.745856: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-28 06:59:00.320479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 2: '0.00.00.00.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m genetic_algorithm(params, data_dict)\n",
      "\u001b[1;32m/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb Cell 37\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(parameters, data_dict, generations, n_parents, verbose)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m offspring_fitness \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m individual \u001b[39min\u001b[39;00m offspring_population:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     phenotype \u001b[39m=\u001b[39m decoder(individual, bit_length)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     params \u001b[39m=\u001b[39m get_params(phenotype, parameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     model, history \u001b[39m=\u001b[39m train_model(params, data_dict[\u001b[39m'\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m'\u001b[39m], data_dict[\u001b[39m'\u001b[39m\u001b[39mX_val\u001b[39m\u001b[39m'\u001b[39m], data_dict[\u001b[39m'\u001b[39m\u001b[39mY_train\u001b[39m\u001b[39m'\u001b[39m], data_dict[\u001b[39m'\u001b[39m\u001b[39mY_val\u001b[39m\u001b[39m'\u001b[39m], verbose \u001b[39m=\u001b[39m verbose)\n",
      "\u001b[1;32m/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb Cell 37\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(chromosome, gene_length)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chromo_length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chromosome)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m start_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, chromo_length, gene_length)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m phenotype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mint\u001b[39m(\u001b[39mstr\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m, chromosome[x:x \u001b[39m+\u001b[39m gene_length]))), \u001b[39m2\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m start_ind])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# is_valid = np.any(phenotype < parameter_lengths - 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m phenotype\n",
      "\u001b[1;32m/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb Cell 37\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chromo_length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chromosome)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m start_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, chromo_length, gene_length)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m phenotype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mint\u001b[39;49m(\u001b[39mstr\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mmap\u001b[39;49m(\u001b[39mstr\u001b[39;49m, chromosome[x:x \u001b[39m+\u001b[39;49m gene_length]))), \u001b[39m2\u001b[39;49m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m start_ind])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# is_valid = np.any(phenotype < parameter_lengths - 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Donovan/Documents/Masters/masters-ed02/coding/model_cnn_ga_1/model_cnn_ga.ipynb#Y204sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m phenotype\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 2: '0.00.00.00.0'"
     ]
    }
   ],
   "source": [
    "genetic_algorithm(params, data_dict, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_population(length = 44, parameter_len = np.array([3, 4, 4, 2, 4, 2, 4, 2, 2, 9, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 3, 0, 1, 3, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(chromosome = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,  0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]), \n",
    "gene_length = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection(generate_population(length = 44, parameter_len = np.array([3, 4, 4, 2, 4, 2, 4, 2, 2, 9, 2])), phenotype=decoder(chromosome = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,  0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]), \n",
    "gene_length = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((np.array([[1,2,3],[1,2,3]]),np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3647436c2f734fd3f72be8f73130b09ecd5d6c908b22991734a3f7b2100497cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
